"""
MockInterview_ValtecTTS.py
Mock Interview s·ª≠ d·ª•ng ValtecTTS qua API (local Gradio server).
Stream mode: chia text th√†nh t·ª´ng c√¢u, ph√°t c√¢u ƒë·∫ßu trong khi synthesize c√¢u ti·∫øp.
"""

import dotenv
dotenv.load_dotenv()

import os
import sys
import re
import wave
import shutil
import time
import pyaudio
import threading
from concurrent.futures import ThreadPoolExecutor, Future
import pygame
from google import genai

# Monkey-patch gradio_client bug
try:
    import gradio_client.utils as _gc_utils
    _orig = _gc_utils._json_schema_to_python_type
    def _patched(schema, defs=None):
        if isinstance(schema, bool):
            return "Any"
        return _orig(schema, defs)
    _gc_utils._json_schema_to_python_type = _patched
except Exception:
    pass

from gradio_client import Client as GradioClient

# === C·∫•u h√¨nh ValtecTTS API ===
VALTEC_API_URL = "http://localhost:7860"  # Local Gradio server
VOICE_NAME = "Thu H√†"  # Thu H√†, Minh ƒê·ª©c, Thanh T√¢m, Quang Huy, Ng·ªçc √Ånh, Ho√†ng Nam

# === C·∫•u h√¨nh √Çm thanh Ghi √¢m ===
FORMAT = pyaudio.paInt16
CHANNELS = 1
RATE = 16000
CHUNK = 1024

pya = pyaudio.PyAudio()
pygame.mixer.init()

# === C·∫•u h√¨nh Gemini ===
client = genai.Client()
MODEL_ID = "gemini-2.5-flash"

system_instruction = """
B·∫°n l√† m·ªôt ng∆∞·ªùi ph·ªèng v·∫•n IT chuy√™n nghi·ªáp, th√¢n thi·ªán v√† h·ªØu √≠ch.
B·∫°n lu√¥n giao ti·∫øp ho√†n to√†n b·∫±ng ti·∫øng Vi·ªát.
Nhi·ªám v·ª• c·ªßa b·∫°n l√† ph·ªèng v·∫•n ·ª©ng vi√™n, ƒë·∫∑t c√¢u h·ªèi t·ª´ng b∆∞·ªõc.
Khi ·ª©ng vi√™n tr·∫£ l·ªùi b·∫±ng gi·ªçng n√≥i (ƒë∆∞·ª£c chuy·ªÉn th√†nh text), h√£y nh·∫≠n x√©t ng·∫Øn g·ªçn, ch·ªâ ra ƒëi·ªÉm t·ªët/ƒëi·ªÉm c·∫ßn c·∫£i thi·ªán, sau ƒë√≥ ƒë·∫∑t c√¢u h·ªèi ti·∫øp theo c√≥ li√™n quan.
Gi·ªçng ƒëi·ªáu c·ªßa b·∫°n t·ª± nhi√™n, r√µ r√†ng.
Lu√¥n k·∫øt th√∫c b·∫±ng m·ªôt c√¢u h·ªèi ti·∫øp n·ªëi. Ch·ªâ n√≥i nh·ªØng th·ª© c·∫ßn ƒë·ªÉ ƒë·ªçc l√™n b·∫±ng text-to-speech.
Tuy·ªát ƒë·ªëi KH√îNG D√ôNG emoji, d·∫•u ngo·∫∑c k√©p, hay c√°c k√Ω t·ª± ƒë·∫∑c bi·ªát kh√≥ ƒë·ªçc.
Khi g·∫∑p t·ª´ vi·∫øt t·∫Øt ti·∫øng Anh, h√£y ƒë·ªçc r√µ t·ª´ng ch·ªØ c√°i theo phi√™n √¢m ti·∫øng Vi·ªát. V√≠ d·ª•: AI th√†nh √Çy-Ai, NLP th√†nh En-Eo-Pi, API th√†nh √Çy-Pi-Ai, SQL th√†nh √ât-Kiu-Eo, HTML th√†nh ·∫æch-Ti-Em-Eo, CSS th√†nh Xi-√ât-√ât, IT th√†nh Ai-Ti, ML th√†nh Em-Eo, DevOps th√†nh ƒê√©p-√ìp.
"""

CONFIG = {
    "system_instruction": system_instruction,
    "temperature": 0.7,
}

# === Bi·∫øn To√†n c·ª•c ===
recording = False
frames = []


# ============================================================
#  Text splitting
# ============================================================

def split_sentences(text):
    """Chia text th√†nh c√°c c√¢u d·ª±a tr√™n d·∫•u ch·∫•m c√¢u ti·∫øng Vi·ªát.
    G·ªôp c√°c ƒëo·∫°n qu√° ng·∫Øn v√†o c√¢u tr∆∞·ªõc ƒë√≥."""
    # T√°ch theo d·∫•u . ! ? v√† gi·ªØ l·∫°i d·∫•u
    parts = re.split(r'(?<=[.!?])\s+', text.strip())
    parts = [p.strip() for p in parts if p.strip()]

    # G·ªôp ƒëo·∫°n ng·∫Øn (<15 k√Ω t·ª±) v√†o c√¢u tr∆∞·ªõc
    merged = []
    for part in parts:
        if merged and len(part) < 15:
            merged[-1] = merged[-1] + " " + part
        else:
            merged.append(part)

    return merged if merged else [text]


# ============================================================
#  TTS API call
# ============================================================

def synthesize_sentence(valtec_client, text, voice_name):
    """G·ªçi API synthesize 1 c√¢u, tr·∫£ v·ªÅ audio file path."""
    result = valtec_client.predict(
        text=text,
        voice_choice=voice_name,
        custom_audio=None,
        speed=1,
        noise_scale=0.667,
        noise_scale_w=0.8,
        api_name="/synthesize_fn"
    )
    audio_info = result[0]
    if isinstance(audio_info, dict):
        return audio_info.get('path', '')
    return str(audio_info)


def play_audio_file(audio_path):
    """Ph√°t 1 file audio b·∫±ng pygame, blocking cho ƒë·∫øn khi xong."""
    if not os.path.exists(audio_path):
        return
    pygame.mixer.music.load(audio_path)
    pygame.mixer.music.play()
    while pygame.mixer.music.get_busy():
        pygame.time.Clock().tick(10)
    pygame.mixer.music.unload()


def play_tts_streamed(valtec_client, text, voice_name):
    """Stream TTS: synthesize c√¢u ti·∫øp theo song song v·ªõi ph√°t c√¢u hi·ªán t·∫°i.
    
    Flow:
      1. Chia text th√†nh c√°c c√¢u
      2. Submit synthesize c√¢u 1 ‚Üí ch·ªù k·∫øt qu·∫£ ‚Üí b·∫Øt ƒë·∫ßu ph√°t
      3. Trong khi ph√°t c√¢u 1, submit synthesize c√¢u 2 (prefetch)
      4. Khi ph√°t xong c√¢u 1, k·∫øt qu·∫£ c√¢u 2 ƒë√£ s·∫µn s√†ng ‚Üí ph√°t ngay
      5. L·∫∑p l·∫°i...
    """
    if not text:
        return

    sentences = split_sentences(text)
    n = len(sentences)
    print(f"\nüîä [ValtecTTS] AI ƒëang ph√°t bi·ªÉu... ({n} c√¢u)")

    executor = ThreadPoolExecutor(max_workers=1)
    t_start = time.time()

    try:
        # Submit c√¢u ƒë·∫ßu ti√™n
        future = executor.submit(synthesize_sentence, valtec_client, sentences[0], voice_name)
        audio_path = future.result()  # Ch·ªù c√¢u 1 xong

        t_first = time.time() - t_start
        print(f"   C√¢u 1/{n} ready in {t_first:.1f}s ‚Äî playing...")

        for i in range(n):
            # Prefetch c√¢u ti·∫øp theo (n·∫øu c√≤n) TR∆Ø·ªöC khi ph√°t c√¢u hi·ªán t·∫°i
            next_future = None
            if i + 1 < n:
                next_future = executor.submit(
                    synthesize_sentence, valtec_client, sentences[i + 1], voice_name
                )

            # Ph√°t audio c√¢u hi·ªán t·∫°i
            play_audio_file(audio_path)

            # L·∫•y k·∫øt qu·∫£ c√¢u ti·∫øp theo (ƒë√£ synthesize song song)
            if next_future:
                audio_path = next_future.result()
                print(f"   C√¢u {i+2}/{n} ready ‚Äî playing...")

        t_total = time.time() - t_start
        print(f"   ‚úì Done ({t_total:.1f}s total, first response: {t_first:.1f}s)")

    except Exception as e:
        print(f"[L·ªói ValtecTTS] {e}")
    finally:
        executor.shutdown(wait=False)


# ============================================================
#  Audio Recording
# ============================================================

def record_audio(filename="user_audio.wav"):
    """Ghi √¢m t·ª´ Micro"""
    global recording, frames
    frames = []

    print("\n" + "=" * 50)
    print("üé§  S·∫µn s√†ng ghi √¢m!")
    input("üëâ  Nh·∫•n [ENTER] ƒë·ªÉ B·∫ÆT ƒê·∫¶U n√≥i...")

    recording = True
    print("\n[ƒêANG GHI √ÇM...] Nh·∫•n [ENTER] l·∫ßn n·ªØa ƒë·ªÉ d·ª´ng")

    stream = pya.open(format=FORMAT, channels=CHANNELS, rate=RATE,
                      input=True, frames_per_buffer=CHUNK)

    def capture():
        while recording:
            try:
                data = stream.read(CHUNK, exception_on_overflow=False)
                frames.append(data)
            except Exception:
                pass

    t = threading.Thread(target=capture)
    t.start()
    input()
    recording = False
    t.join()

    print("[ƒê√É L∆ØU] ƒêang g·ª≠i c√¢u tr·∫£ l·ªùi l√™n Gemini...")

    stream.stop_stream()
    stream.close()

    wf = wave.open(filename, 'wb')
    wf.setnchannels(CHANNELS)
    wf.setsampwidth(pya.get_sample_size(FORMAT))
    wf.setframerate(RATE)
    wf.writeframes(b''.join(frames))
    wf.close()
    return filename


# ============================================================
#  Main
# ============================================================

def main():
    print("=" * 60)
    print("  Mock Interview ‚Äî ValtecTTS (Local API + Stream)")
    print("=" * 60)

    # 1. Connect to local ValtecTTS Gradio server
    print(f"[H·ªá th·ªëng] Connecting to ValtecTTS ({VALTEC_API_URL})...")
    valtec_client = GradioClient(VALTEC_API_URL)
    print(f"[H·ªá th·ªëng] ‚úì Connected! Gi·ªçng AI: {VOICE_NAME}")

    # 2. Kh·ªüi t·∫°o Gemini chat
    chat = client.chats.create(model=MODEL_ID, config=CONFIG)
    print("\n[H·ªá th·ªëng] ƒêang y√™u c·∫ßu AI b·∫Øt ƒë·∫ßu cu·ªôc ph·ªèng v·∫•n...")

    try:
        response = chat.send_message("H√£y b·∫Øt ƒë·∫ßu cu·ªôc ph·ªèng v·∫•n b·∫±ng ti·∫øng Vi·ªát ngay b√¢y gi·ªù.")
        if response.text:
            print("\nü§ñ AI:", response.text)
            play_tts_streamed(valtec_client, response.text, VOICE_NAME)
    except Exception as e:
        print("L·ªói khi k·∫øt n·ªëi:", e)
        return

    temp_wav = "temp_user_response.wav"

    # 3. V√≤ng l·∫∑p ph·ªèng v·∫•n
    while True:
        try:
            record_audio(temp_wav)

            print("\n[H·ªá th·ªëng] AI ƒëang l·∫Øng nghe v√† suy nghƒ©...")
            audio_file = client.files.upload(file=temp_wav)
            response = chat.send_message(audio_file)

            if response.text:
                print("\nü§ñ AI:", response.text)
                play_tts_streamed(valtec_client, response.text, VOICE_NAME)

        except KeyboardInterrupt:
            print("\n\n[H·ªá th·ªëng] ƒê√£ d·ª´ng ch∆∞∆°ng tr√¨nh (Ctrl+C).")
            break
        except Exception as e:
            print(f"\n[L·ªói] {e}")

    # Cleanup
    if os.path.exists(temp_wav):
        os.remove(temp_wav)
    pya.terminate()
    pygame.quit()
    print("ƒê√£ k·∫øt th√∫c Mock Interview.")


if __name__ == "__main__":
    if not os.getenv("GEMINI_API_KEY"):
        print("L·ªñI: Ch∆∞a c·∫•u h√¨nh GEMINI_API_KEY trong file .env")
        sys.exit(1)
    main()

import dotenv
dotenv.load_dotenv()

import os
import sys
import wave
import pyaudio
import threading
import asyncio
import edge_tts
import pygame
from google import genai

# === Cáº¥u hÃ¬nh Ã‚m thanh Ghi Ã¢m ===
FORMAT = pyaudio.paInt16
CHANNELS = 1
RATE = 16000
CHUNK = 1024

pya = pyaudio.PyAudio()
pygame.mixer.init()

# === Cáº¥u hÃ¬nh Text-To-Speech (Microsoft Edge Neural) ===
# Giá»ng ná»¯ tiáº¿ng Viá»‡t cháº¥t lÆ°á»£ng cao siÃªu tá»± nhiÃªn
VOICE_NAME = "vi-VN-HoaiMyNeural" 
print(f"[Há»‡ thá»‘ng] ÄÃ£ cáº¥u hÃ¬nh Giá»ng Ä‘á»c AI Trá»£ lÃ½: {VOICE_NAME}")

# === Cáº¥u hÃ¬nh Gemini ===
client = genai.Client() 
# DÃ¹ng báº£n text tá»‘c Ä‘á»™ cao siÃªu á»•n Ä‘á»‹nh
MODEL_ID = "gemini-2.5-flash" 

system_instruction = """
Báº¡n lÃ  má»™t ngÆ°á»i phá»ng váº¥n IT chuyÃªn nghiá»‡p, thÃ¢n thiá»‡n vÃ  há»¯u Ã­ch.
Báº¡n luÃ´n giao tiáº¿p hoÃ n toÃ n báº±ng tiáº¿ng Viá»‡t.
Nhiá»‡m vá»¥ cá»§a báº¡n lÃ  phá»ng váº¥n á»©ng viÃªn, Ä‘áº·t cÃ¢u há»i tá»«ng bÆ°á»›c.
Khi á»©ng viÃªn tráº£ lá»i báº±ng giá»ng nÃ³i (Ä‘Æ°á»£c chuyá»ƒn thÃ nh text), hÃ£y nháº­n xÃ©t ngáº¯n gá»n, chá»‰ ra Ä‘iá»ƒm tá»‘t/Ä‘iá»ƒm cáº§n cáº£i thiá»‡n, sau Ä‘Ã³ Ä‘áº·t cÃ¢u há»i tiáº¿p theo cÃ³ liÃªn quan.
Giá»ng Ä‘iá»‡u cá»§a báº¡n tá»± nhiÃªn, rÃµ rÃ ng.
LuÃ´n káº¿t thÃºc báº±ng má»™t cÃ¢u há»i tiáº¿p ná»‘i. Chá»‰ nÃ³i nhá»¯ng thá»© cáº§n Ä‘á»ƒ Ä‘á»c lÃªn báº±ng text-to-speech.
Tuyá»‡t Ä‘á»‘i KHÃ”NG DÃ™NG emoji, dáº¥u ngoáº·c kÃ©p, hay cÃ¡c kÃ½ tá»± Ä‘áº·c biá»‡t khÃ³ Ä‘á»c.
"""

CONFIG = {
    "system_instruction": system_instruction,
    "temperature": 0.7,
}

# === Khai bÃ¡o Biáº¿n ToÃ n cá»¥c cho Ghi Ã¢m ===
recording = False
frames = []

def record_audio(filename="user_audio.wav"):
    """Ghi Ã¢m tá»« Micro sá»­ dá»¥ng input() vÃ  luá»“ng (Thread)"""
    global recording, frames
    frames = []
    
    print("\n" + "="*50)
    print("ğŸ¤  Sáºµn sÃ ng ghi Ã¢m!")
    input("ğŸ‘‰  Nháº¥n phÃ­m [ENTER] Ä‘á»ƒ Báº®T Äáº¦U nÃ³i...")
    
    recording = True
    print("\n[ÄANG GHI Ã‚M...] (HÃ£y nÃ³i Ä‘i, nháº¥n [ENTER] láº§n ná»¯a Ä‘á»ƒ dá»«ng)")
    
    stream = pya.open(format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK)
    
    def capture_audio():
        while recording:
            try:
                data = stream.read(CHUNK, exception_on_overflow=False)
                frames.append(data)
            except Exception:
                pass

    t = threading.Thread(target=capture_audio)
    t.start()
    
    # Äá»£i ngÆ°á»i dÃ¹ng nháº¥n Enter láº§n 2 Ä‘á»ƒ dá»«ng
    input()
    recording = False
    t.join()
    
    print("[ÄÃƒ LÆ¯U] Äang gá»­i cÃ¢u tráº£ lá»i lÃªn Gemini...")
            
    stream.stop_stream()
    stream.close()

    # LÆ°u ra file WAV táº¡m thá»i
    wf = wave.open(filename, 'wb')
    wf.setnchannels(CHANNELS)
    wf.setsampwidth(pya.get_sample_size(FORMAT))
    wf.setframerate(RATE)
    wf.writeframes(b''.join(frames))
    wf.close()
    
    return filename

async def play_text_to_speech(text, filename="ai_audio.mp3"):
    """Sá»­ dá»¥ng edge-tts tá»•ng há»£p giá»ng nÃ³i Ä‘a ngÃ´n ngá»¯ siÃªu mÆ°á»£t vÃ  phÃ¡t mp3"""
    if not text: return
    try:
        print("\nğŸ”Š [Há»‡ thá»‘ng] AI Ä‘ang phÃ¡t biá»ƒu...")
        communicate = edge_tts.Communicate(text, VOICE_NAME)
        await communicate.save(filename)
        
        pygame.mixer.music.load(filename)
        pygame.mixer.music.play()
        
        while pygame.mixer.music.get_busy():
            pygame.time.Clock().tick(10)
            
        pygame.mixer.music.unload()
    except Exception as e:
        print(f"[Lá»—i Edge TTS] {e}")

# === VÃ²ng láº·p chÃ­nh (Chat Session) ===
def main():
    print("Khá»Ÿi Ä‘á»™ng phiÃªn Mock Interview (Text + Edge Neural TTS)...")
    
    chat = client.chats.create(
        model=MODEL_ID,
        config=CONFIG
    )
    
    print("\n[Há»‡ thá»‘ng] Äang yÃªu cáº§u AI báº¯t Ä‘áº§u cuá»™c phá»ng váº¥n...")
    try:
        response = chat.send_message("HÃ£y báº¯t Ä‘áº§u cuá»™c phá»ng váº¥n báº±ng tiáº¿ng Viá»‡t ngay bÃ¢y giá».")
        
        if response.text:
            print("\nğŸ¤– AI:", response.text)
            asyncio.run(play_text_to_speech(response.text))
            
    except Exception as e:
        print("Lá»—i khi káº¿t ná»‘i ban Ä‘áº§u:", e)
        return

    temp_wav = "temp_user_response.wav"
    ai_mp3 = "ai_audio.mp3"
    
    while True:
        try:
            # 1. Ghi Ã¢m ngÆ°á»i dÃ¹ng
            record_audio(temp_wav)
            
            # 2. Upload file Ã¢m thanh lÃªn Gemini
            print("\n[Há»‡ thá»‘ng] AI Ä‘ang láº¯ng nghe vÃ  suy nghÄ©...")
            audio_file = client.files.upload(file=temp_wav)
            
            # 3. Gá»­i file vÃ o Chat Session
            response = chat.send_message(audio_file)
            
            # 4. Hiá»ƒn thá»‹ Text vÃ  PhÃ¡t Audio báº±ng TTS
            if response.text:
                print("\nğŸ¤– AI:", response.text)
                asyncio.run(play_text_to_speech(response.text, ai_mp3))
                
        except KeyboardInterrupt:
            print("\n\n[Há»‡ thá»‘ng] NgÆ°á»i dÃ¹ng Ä‘Ã£ dá»«ng chÆ°Æ¡ng trÃ¬nh (Ctrl+C).")
            break
        except Exception as e:
            print(f"\n[Lá»—i] ÄÃ£ xáº£y ra sá»± cá»‘: {e}")
            
    # Cleanup dá»n dáº¹p biáº¿n, file táº¡m
    if os.path.exists(temp_wav): os.remove(temp_wav)
    if os.path.exists(ai_mp3): os.remove(ai_mp3)
    pya.terminate()
    pygame.quit()
    print("ÄÃ£ káº¿t thÃºc Mock Interview.")

if __name__ == "__main__":
    if not os.getenv("GEMINI_API_KEY"):
        print("Lá»–I: ChÆ°a cáº¥u hÃ¬nh GEMINI_API_KEY trong file .env")
        sys.exit(1)
    
    main()
